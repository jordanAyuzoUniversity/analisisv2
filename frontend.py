import streamlit as st

def render_interface(model, predict_fn):
    st.set_page_config(page_title="Chat de Sentimientos", page_icon="ğŸ’¬")
    st.title("Chat de AnÃ¡lisis de Sentimientos")

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    # Mostrar historial
    for entry in st.session_state.chat_history:
        with st.chat_message("user"):
            st.markdown(entry["user"])
        with st.chat_message("assistant"):
            st.markdown(entry["bot"], unsafe_allow_html=True)

    user_input = st.chat_input("Escribe tu mensaje...")

    if user_input:
        # Mostrar mensaje del usuario
        st.chat_message("user").markdown(user_input)

        # Comando especial /info
        if user_input.strip().lower() == "/info":
            info_msg = (
                "ğŸ“˜ **InformaciÃ³n del modelo:**  \n"
                "Este modelo fue desarrollado usando la tÃ©cnica de *stacking* como parte de un proyecto "
                "para la materia **Reconocimiento de Patrones** en la **Universidad TecnolÃ³gica de la Mixteca**.  \n\n"
                "ğŸ”¤ EstÃ¡ diseÃ±ado para analizar opiniones escritas en **inglÃ©s**."
            )
            bot_response = info_msg
        else:
            prediction = predict_fn(model, user_input)
            sentiment = "Positivo" if prediction == 1 else "Negativo"
            icon = "âœ…" if prediction == 1 else "âŒ"
            bot_response = f"{icon} Sentimiento **{sentiment.upper()}**"

        # Mostrar respuesta del bot
        st.chat_message("assistant").markdown(bot_response, unsafe_allow_html=True)

        # Guardar en historial
        st.session_state.chat_history.append({
            "user": user_input,
            "bot": bot_response
        })

    # BotÃ³n para limpiar conversaciÃ³n
    if st.button("ğŸ§¹ Limpiar conversaciÃ³n"):
        st.session_state.chat_history = []
        st.rerun()
